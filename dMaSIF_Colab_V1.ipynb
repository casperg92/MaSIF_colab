{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casperg92/MaSIF_colab/blob/main/dMaSIF_Colab_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# dMaSIF site\n",
        "Protein binding is determined by the chemical and geometric features between their surfaces. differentiable Molecular Surface Interaction Fingerprinting (dMaSIF) site is a geometric deep learning framework trained on these surface 'fingerprints' to identify potential protein binding sites. For more details, check out the original papers:\n",
        "\n",
        "1) [Gainza, P., Sverrisson, F., Monti, F., Rodola, E., Boscaini, D., Bronstein, M. M., & Correia, B. E. (2020). Deciphering interaction fingerprints from protein molecular surfaces using geometric deep learning. Nature Methods, 17(2), 184-192.](https://doi.org/10.1038/s41592-019-0666-6)\n",
        "\n",
        "2) [Sverrisson, F., Feydy, J., Correia, B. E., & Bronstein, M. M. (2021). Fast end-to-end learning on protein surfaces. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 15272-15281).](http://dx.doi.org/10.1109/CVPR46437.2021.01502)"
      ],
      "metadata": {
        "id": "Ec5_Lo20XBbl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Upload a pdb file?\n",
        "#@markdown pdb files will be uploaded to the '/content/pdbs' folder.\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Create folder for the pdbs\n",
        "pred_dir = '/content/pdbs'\n",
        "isExist = os.path.exists(pred_dir)\n",
        "if not isExist:\n",
        "  os.makedirs(pred_dir)\n",
        "\n",
        "upload_file = False #@param {type:\"boolean\"}\n",
        "\n",
        "%cd -q /content/pdbs\n",
        "if upload_file:\n",
        "  uploaded = files.upload()\n",
        "%cd -q /content"
      ],
      "metadata": {
        "id": "J7MaEAYCpEJ6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Change pdb path and chain name(s), then hit `Runtime` -> `Run all`\n",
        "#@markdown Note: the pdb file cannot contain an underscore ('_') in its name.\n",
        "import os\n",
        "import glob\n",
        "\n",
        "\n",
        "\n",
        "# target pdb\n",
        "target_pdb = \"/content/MaSIF_colab/example/monomerexample.pdb\" #@param {type:\"string\"}\n",
        "target_name = target_pdb.split('/')\n",
        "target_name = target_name[-1].split('.')\n",
        "\n",
        "if target_name[-1] == 'pdb':\n",
        "  target_name = target_name[0]\n",
        "else:\n",
        "  print('Please upload a valid .pdb file!')\n",
        "\n",
        "chain_name = 'A' #@param {type:\"string\"}\n",
        "chains = [chain_name]\n",
        "\n",
        "# Path to MaSIF weights\n",
        "#@markdown A resolution of 0.7 Angstrom gives a higher point cloud density and a higher performance. Different radii settings do not seem to impact performance.\n",
        "model_resolution = '0.7 Angstrom' #@param [\"1 Angstrom\", \"0.7 Angstrom\"]\n",
        "patch_radius = '9 Angstrom' #@param [\"9 Angstrom\", \"12 Angstrom\"]\n",
        "\n",
        "\n",
        "if patch_radius == '9 Angstrom':\n",
        "  if model_resolution == '1 Angstrom':\n",
        "    model_path = '/content/MaSIF_colab/models/dMaSIF_site_3layer_16dims_9A_100sup_epoch64'\n",
        "    resolution = 1.0\n",
        "    radius = 9\n",
        "    sup_sampling = 100\n",
        "  else:\n",
        "    model_path = '/content/MaSIF_colab/models/dMaSIF_site_3layer_16dims_9A_0.7res_150sup_epoch85'\n",
        "    resolution = 0.7\n",
        "    radius = 9\n",
        "    supsampling = 150\n",
        "\n",
        "elif patch_radius == '12 Angstrom':\n",
        "  if model_resolution == '1 Angstrom':\n",
        "    model_path = '/content/MaSIF_colab/models/dMaSIF_site_3layer_16dims_12A_100sup_epoch71'\n",
        "    resolution = 1.0\n",
        "    radius = 12\n",
        "    supsampling = 100\n",
        "  else:\n",
        "    model_path = '/content/MaSIF_colab/models/dMaSIF_site_3layer_16dims_12A_0.7res_150sup_epoch59'\n",
        "    resolution = 0.7\n",
        "    radius = 12\n",
        "    supsampling = 100\n",
        "\n",
        "\n",
        "# create new folders\n",
        "# chain dir\n",
        "chains_dir = '/content/chains'\n",
        "isExist = os.path.exists(chains_dir)\n",
        "if not isExist:\n",
        "  os.makedirs(chains_dir)\n",
        "else:\n",
        "  files = glob.glob(chains_dir + '/*')\n",
        "  for f in files:\n",
        "    os.remove(f)\n",
        "\n",
        "# npy folder\n",
        "npy_dir = '/content/npys'\n",
        "isExist = os.path.exists(npy_dir)\n",
        "if not isExist:\n",
        "  os.makedirs(npy_dir)\n",
        "else:\n",
        "  files = glob.glob(npy_dir + '/*')\n",
        "  for f in files:\n",
        "    os.remove(f)\n",
        "\n",
        "# Create folder for the embeddings\n",
        "pred_dir = '/content/preds'\n",
        "isExist = os.path.exists(pred_dir)\n",
        "if not isExist:\n",
        "  os.makedirs(pred_dir)\n",
        "else:\n",
        "  files = glob.glob(pred_dir + '/*')\n",
        "  for f in files:\n",
        "    os.remove(f)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "HKgFCDrM1dO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "WIC7ZAPgYp_v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219,
          "referenced_widgets": [
            "b3b7089a0b4043cfb5490aa590aa7b1a"
          ]
        },
        "outputId": "e2fea237-aacd-4003-f21f-07ab53fb9e21",
        "cellView": "form"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3b7089a0b4043cfb5490aa590aa7b1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/a8874ba6619b6106/manager.min.js"
                }
              }
            }
          },
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading MaSIF..\n",
            "Installing PyTorch..\n",
            "Installing PyTorch Geometric..\n",
            "Installing PyKeops..\n",
            "Installing BioPython..\n",
            "Installing plyfile..\n",
            "Installing pyvtk..\n",
            "Installing nglview..\n",
            "Installing pdbparser..\n",
            "Installing reduce..\n",
            "fatal: destination path 'reduce' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "#@title Install dependencies\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "#Manually set p_bar\n",
        "def update_pbar(p_bar, c=1):\n",
        "  p_bar.update(c)\n",
        "  p_bar.refresh()\n",
        "\n",
        "p_bar = tqdm(range(10))\n",
        "\n",
        "# Switch to CUDA 11.1\n",
        "%cd -q /usr/local/\n",
        "!rm -rf cuda > /dev/null\n",
        "!ln -s /usr/local/cuda-11.1 /usr/local/cuda > /dev/null\n",
        "#!stat cuda\n",
        "\n",
        "# Git clone MaSIF for Colab (including examples and weights)\n",
        "print('Downloading MaSIF..')\n",
        "%cd -q /content\n",
        "!rm -fr MaSIF_colab > /dev/null\n",
        "!git clone --quiet https://github.com/casperg92/MaSIF_colab.git > /dev/null\n",
        "update_pbar(p_bar)\n",
        "\n",
        "\n",
        "# Downgrade pytorch to make it compatable with pytorch geometric\n",
        "print('Installing PyTorch..')\n",
        "!pip install torch==1.8.1+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html &> /dev/null\n",
        "update_pbar(p_bar)\n",
        "print('Installing PyTorch Geometric..')\n",
        "!pip install torch-scatter==2.0.7 -f https://data.pyg.org/whl/torch-1.8.1+cu111.html &> /dev/null\n",
        "!pip install torch-sparse==0.6.11 -f https://data.pyg.org/whl/torch-1.8.1+cu111.html &> /dev/null\n",
        "!pip install torch-cluster==1.5.9 -f https://data.pyg.org/whl/torch-1.8.1+cu111.html &> /dev/null\n",
        "!pip install torch-geometric==1.6.1 &> /dev/null\n",
        "update_pbar(p_bar)\n",
        "print('Installing PyKeops..')\n",
        "!pip install git+https://github.com/getkeops/keops.git@python_engine &> /dev/null\n",
        "update_pbar(p_bar)\n",
        "print('Installing BioPython..')\n",
        "!pip install biopython &> /dev/null\n",
        "update_pbar(p_bar)\n",
        "print('Installing plyfile..')\n",
        "!pip install plyfile &> /dev/null\n",
        "update_pbar(p_bar)\n",
        "print('Installing pyvtk..')\n",
        "!pip install pyvtk &> /dev/null\n",
        "update_pbar(p_bar)\n",
        "print('Installing nglview..')\n",
        "!pip install -q nglview &> /dev/null\n",
        "update_pbar(p_bar)\n",
        "print('Installing pdbparser..')\n",
        "!pip install pdbparser &> /dev/null\n",
        "update_pbar(p_bar)\n",
        "print('Installing reduce..')\n",
        "!git clone --quiet https://github.com/rlabduke/reduce > /dev/null\n",
        "!cmake reduce &> /dev/null\n",
        "!make &> /dev/null\n",
        "!sudo make install &> /dev/null\n",
        "update_pbar(p_bar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "rPF7AF9rlCIO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Load functions\n",
        "import sys\n",
        "sys.path.append(\"MaSIF_colab\") \n",
        "sys.path.append(\"MaSIF_colab/data_preprocessing\") \n",
        "\n",
        "import numpy as np\n",
        "import pykeops\n",
        "import torch\n",
        "from Bio.PDB import *\n",
        "from data_preprocessing.download_pdb import convert_to_npy\n",
        "from torch_geometric.data import DataLoader\n",
        "from torch_geometric.transforms import Compose\n",
        "import argparse\n",
        "import shutil\n",
        "\n",
        "# Custom data loader and model:\n",
        "from data import ProteinPairsSurfaces, PairData, CenterPairAtoms, load_protein_pair\n",
        "from data import RandomRotationPairAtoms, NormalizeChemFeatures, iface_valid_filter\n",
        "from model import dMaSIF\n",
        "from data_iteration import iterate\n",
        "from helper import *\n",
        "\n",
        "# For showing the plot in nglview\n",
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()\n",
        "import nglview as ng\n",
        "#import ipywidgets as widgets\n",
        "from pdbparser.pdbparser import pdbparser\n",
        "\n",
        "# For downloading files\n",
        "from google.colab import files\n",
        "\n",
        "def generate_descr(model_path, output_path, pdb_file, npy_directory, radius, resolution,supsampling):\n",
        "    \"\"\"Generat descriptors for a MaSIF site model\"\"\"\n",
        "    parser = argparse.ArgumentParser(description=\"Network parameters\")\n",
        "    parser.add_argument(\"--experiment_name\", type=str, default=model_path)\n",
        "    parser.add_argument(\"--use_mesh\", type=bool, default=False)\n",
        "    parser.add_argument(\"--embedding_layer\",type=str,default=\"dMaSIF\")\n",
        "    parser.add_argument(\"--curvature_scales\",type=list,default=[1.0, 2.0, 3.0, 5.0, 10.0])\n",
        "    parser.add_argument(\"--resolution\",type=float,default=resolution)\n",
        "    parser.add_argument(\"--distance\",type=float,default=1.05)\n",
        "    parser.add_argument(\"--variance\",type=float,default=0.1)\n",
        "    parser.add_argument(\"--sup_sampling\", type=int, default=supsampling)\n",
        "    parser.add_argument(\"--atom_dims\",type=int,default=6)\n",
        "    parser.add_argument(\"--emb_dims\",type=int,default=16)\n",
        "    parser.add_argument(\"--in_channels\",type=int,default=16)\n",
        "    parser.add_argument(\"--orientation_units\",type=int,default=16)\n",
        "    parser.add_argument(\"--unet_hidden_channels\",type=int,default=8)\n",
        "    parser.add_argument(\"--post_units\",type=int,default=8)\n",
        "    parser.add_argument(\"--n_layers\", type=int, default=3)\n",
        "    parser.add_argument(\"--radius\", type=float, default=radius)\n",
        "    parser.add_argument(\"--k\",type=int,default=40)\n",
        "    parser.add_argument(\"--dropout\",type=float,default=0.0)\n",
        "    parser.add_argument(\"--site\", type=bool, default=True) # set to true for site model\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=1)\n",
        "    parser.add_argument(\"--search\",type=bool,default=False) # Set to true for search model\n",
        "    parser.add_argument(\"--single_pdb\",type=str,default=pdb_file)\n",
        "    parser.add_argument(\"--seed\", type=int, default=42)\n",
        "    parser.add_argument(\"--random_rotation\",type=bool,default=False)\n",
        "    parser.add_argument(\"--device\", type=str, default=\"cpu\")\n",
        "    #parser.add_argument(\"--single_protein\",type=bool,default=True)\n",
        "    parser.add_argument(\"--single_protein\",type=bool,default=True) # set to false for site\n",
        "    parser.add_argument(\"--no_chem\", type=bool, default=False)\n",
        "    parser.add_argument(\"--no_geom\", type=bool, default=False)\n",
        "    \n",
        "    args = parser.parse_args(\"\")\n",
        "\n",
        "    model_path = args.experiment_name\n",
        "    save_predictions_path = Path(output_path)\n",
        "    \n",
        "    # Ensure reproducability:\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.manual_seed(args.seed)\n",
        "    torch.cuda.manual_seed_all(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "\n",
        "    # Load the train and test datasets:\n",
        "    transformations = (\n",
        "        Compose([NormalizeChemFeatures(), CenterPairAtoms(), RandomRotationPairAtoms()])\n",
        "        if args.random_rotation\n",
        "        else Compose([NormalizeChemFeatures()])\n",
        "    )\n",
        "    \n",
        "    if args.single_pdb != \"\":\n",
        "        single_data_dir = Path(npy_directory)\n",
        "        test_dataset = [load_protein_pair(args.single_pdb, single_data_dir, single_pdb=True)]\n",
        "        test_pdb_ids = [args.single_pdb]\n",
        "\n",
        "    # PyTorch geometric expects an explicit list of \"batched variables\":\n",
        "    batch_vars = [\"xyz_p1\", \"xyz_p2\", \"atom_coords_p1\", \"atom_coords_p2\"]\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=args.batch_size, follow_batch=batch_vars\n",
        "    )\n",
        "\n",
        "    net = dMaSIF(args)\n",
        "    # net.load_state_dict(torch.load(model_path, map_location=args.device))\n",
        "    net.load_state_dict(torch.load(model_path, map_location=args.device)[\"model_state_dict\"])\n",
        "    net = net.to(args.device)\n",
        "\n",
        "    # Perform one pass through the data:\n",
        "    info = iterate(\n",
        "        net,\n",
        "        test_loader,\n",
        "        None,\n",
        "        args,\n",
        "        test=True,\n",
        "        save_path=save_predictions_path,\n",
        "        pdb_ids=test_pdb_ids,\n",
        "    )\n",
        "    return info\n",
        "\n",
        "  \n",
        "\n",
        "def show_pointcloud(main_pdb, coord_file, emb_file):\n",
        "  # Normalize embedding to represent a b-factor value between 0-100\n",
        "  b_factor = []\n",
        "  for emb in emb_file:\n",
        "      b_factor.append(emb[-2])\n",
        "  \n",
        "  # b_factor = [(float(i)-min(b_factor))/(max(b_factor)-min(b_factor)) for i in b_factor]\n",
        "\n",
        "  # writing a psudo pdb of all points using their coordinates and H atom.\n",
        "  records = []\n",
        "\n",
        "  for i in range(len(coord_file)):\n",
        "      points = coord_file[i]\n",
        "      x_coord = points[0]\n",
        "      y_coord = points[1]\n",
        "      z_coord = points[2]\n",
        "\n",
        "      records.append( { \"record_name\"       : 'ATOM',\n",
        "                    \"serial_number\"     : len(records)+1,\n",
        "                    \"atom_name\"         : 'H',\n",
        "                    \"location_indicator\": '',\n",
        "                    \"residue_name\"      : 'XYZ',\n",
        "                    \"chain_identifier\"  : '',\n",
        "                    \"sequence_number\"   : len(records)+1,\n",
        "                    \"code_of_insertion\" : '',\n",
        "                    \"coordinates_x\"     : x_coord,\n",
        "                    \"coordinates_y\"     : y_coord,\n",
        "                    \"coordinates_z\"     : z_coord,\n",
        "                    \"occupancy\"         : 1.0,\n",
        "                    \"temperature_factor\": b_factor[i]*100,\n",
        "                    \"segment_identifier\": '',\n",
        "                    \"element_symbol\"    : 'H',\n",
        "                    \"charge\"            : '',\n",
        "                    } )\n",
        "    \n",
        "  pdb = pdbparser()\n",
        "  pdb.records = records\n",
        "\n",
        "  pdb.export_pdb(\"pointcloud.pdb\")\n",
        "\n",
        "  # reading the psudo PDB we generated above for the point cloud.\n",
        "  coordPDB = \"pointcloud.pdb\"\n",
        "  view = ng.NGLWidget()\n",
        "  view.add_component(ng.FileStructure(os.path.join(\"/content\", coordPDB)), defaultRepresentation=False)\n",
        "\n",
        "  # representation with our customized colorscheme.\n",
        "  view.add_representation('point', \n",
        "                          useTexture = 1,\n",
        "                          pointSize = 2,\n",
        "                          colorScheme = \"bfactor\",\n",
        "                          colorDomain = [100.0, 0.0], \n",
        "                          colorScale = 'rwb',\n",
        "                          selection='_H')\n",
        "\n",
        "  view.add_component(ng.FileStructure(os.path.join(\"/content\", main_pdb)))\n",
        "  view.background = 'black'\n",
        "  return view\n",
        "\n",
        "def show_structure(main_pdb):\n",
        "  # reading the psudo PDB we generated above for the point cloud.\n",
        "  view = ng.NGLWidget()\n",
        "\n",
        "  view.add_component(ng.FileStructure(main_pdb), defaultRepresentation=False)\n",
        "  view.add_representation(\"cartoon\", colorScheme = \"bfactor\", colorScale = 'rwb', colorDomain = [100.0, 0.0])\n",
        "  view.add_representation(\"ball+stick\", colorScheme = \"bfactor\", colorScale = 'rwb', colorDomain = [100.0, 0.0])\n",
        "  view.background = 'black'\n",
        "  return view"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run MaSIF\n",
        "# Protonate the pdb file using reduce\n",
        "tmp_pdb = '/content/pdbs/tmp_1.pdb'\n",
        "shutil.copyfile(target_pdb, tmp_pdb)\n",
        "\n",
        "# Remove protons if there are any\n",
        "!reduce -Trim -Quiet /content/pdbs/tmp_1.pdb > /content/pdbs/tmp_2.pdb\n",
        "# Add protons\n",
        "!reduce -HIS -Quiet /content/pdbs/tmp_2.pdb > /content/pdbs/tmp_3.pdb\n",
        "\n",
        "tmp_pdb = '/content/pdbs/tmp_3.pdb'\n",
        "shutil.copyfile(tmp_pdb, target_pdb)\n",
        "\n",
        "!rm /content/pdbs/tmp_1.pdb /content/pdbs/tmp_2.pdb /content/pdbs/tmp_3.pdb\n",
        "\n",
        "# Generate the surface features\n",
        "convert_to_npy(target_pdb, chains_dir, npy_dir, chains)\n",
        "\n",
        "# Generate the embeddings\n",
        "pdb_name = \"{n}_{c}_{c}\".format(n= target_name, c=chain_name)\n",
        "info = generate_descr(model_path, pred_dir, pdb_name, npy_dir, radius, resolution, supsampling)\n",
        "\n",
        "# In info I hardcoded memory usage to 0 so MaSIF would run on the CPU. We might want to change this."
      ],
      "metadata": {
        "id": "ny2s1giV1WFP",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "162a0751-9504-4466-fbee-d0fc54c6bd68"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-a8c0d109c4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Protonate the pdb file using reduce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtmp_pdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/pdbs/tmp_1.pdb'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_pdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtmp_pdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Remove protons if there are any\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"'/content/pdbs/PD1.pdb\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate PDBs for hotspot atoms and residues\n",
        "list_hotspot_residues = False #@param {type:\"boolean\"}\n",
        "\n",
        "from Bio.PDB.PDBParser import PDBParser\n",
        "from scipy.spatial.distance import cdist\n",
        "\n",
        "parser=PDBParser(PERMISSIVE=1)\n",
        "structure=parser.get_structure(\"structure\", target_pdb)\n",
        "\n",
        "coord = np.load(\"preds/{n}_{c}_predcoords.npy\".format(n= target_name, c=chain_name))\n",
        "embedding = np.load(\"/content/preds/{n}_{c}_predfeatures_emb1.npy\".format(n= target_name, c=chain_name))\n",
        "atom_coords = np.stack([atom.get_coord() for atom in structure.get_atoms()])\n",
        "\n",
        "b_factor = embedding[:, -2]\n",
        "# b_factor = (b_factor - min(b_factor)) / (max(b_factor) - min(b_factor))\n",
        "\n",
        "dists = cdist(atom_coords, coord)\n",
        "nn_ind = np.argmin(dists, axis=1)\n",
        "dists = dists[np.arange(len(dists)), nn_ind]\n",
        "atom_b_factor = b_factor[nn_ind]\n",
        "dist_thresh = 2.0\n",
        "atom_b_factor[dists > dist_thresh] = 0.0\n",
        "\n",
        "for i, atom in enumerate(structure.get_atoms()):\n",
        "    atom.set_bfactor(atom_b_factor[i] * 100)\n",
        "\n",
        "# Create folder for the embeddings\n",
        "pred_dir = '/content/output'\n",
        "os.makedirs(pred_dir, exist_ok=True)\n",
        "\n",
        "# Save pdb file with per-atom b-factors\n",
        "io = PDBIO()\n",
        "io.set_structure(structure)\n",
        "io.save(\"/content/output/per_atom_binding.pdb\")\n",
        "\n",
        "atom_residues = np.array([atom.get_parent().id[1] for atom in structure.get_atoms()])\n",
        "\n",
        "hotspot_res = {}\n",
        "for residue in structure.get_residues():\n",
        "    res_id = residue.id[1]\n",
        "    res_b_factor = np.max(atom_b_factor[atom_residues == res_id])\n",
        "    hotspot_res[res_id] = res_b_factor\n",
        "    for atom in residue.get_atoms():\n",
        "        atom.set_bfactor(res_b_factor * 100)\n",
        "\n",
        "# Save pdb file with per-residue b-factors\n",
        "io = PDBIO()\n",
        "io.set_structure(structure)\n",
        "io.save(\"/content/output/per_resi_binding.pdb\")\n",
        "\n",
        "if list_hotspot_residues:\n",
        "  print('Sorted on residue contribution (high to low')\n",
        "  for w in sorted(hotspot_res, key=hotspot_res.get, reverse=True):\n",
        "    print(w, hotspot_res[w])"
      ],
      "metadata": {
        "id": "t4sc3RVIeS6u",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Plot output\n",
        "#@markdown Blue identifies non-binding and red identifies binding interaction sites. Rerun this cell if you want to change the plotted structure.\n",
        "plot_structure = 'Pointcloud' #@param [\"Pointcloud\", \"Residues\", \"Atoms\"]\n",
        "\n",
        "## file addresses\n",
        "if plot_structure == 'Pointcloud':\n",
        "  view = show_pointcloud(target_pdb, coord, embedding)\n",
        "elif plot_structure == \"Residues\":\n",
        "  view = show_structure('/content/output/per_resi_binding.pdb')\n",
        "elif plot_structure == \"Atoms\":\n",
        "  view = show_structure('/content/output/per_atom_binding.pdb')\n",
        "\n",
        "view"
      ],
      "metadata": {
        "id": "JrrqzlIZDJ6H",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download predictions\n",
        "!cp /content/preds/* /content/output\n",
        "!cp /content/pointcloud.pdb /content/output\n",
        "!zip -r /content/output.zip output\n",
        "files.download(\"/content/output.zip\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "hbBdtjFyA-x9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "9cc8397f-09dc-4e5c-d4bf-cc010c290201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: output/ (stored 0%)\n",
            "  adding: output/monomerexample_A_predcoords.npy (deflated 9%)\n",
            "  adding: output/pointcloud.pdb (deflated 77%)\n",
            "  adding: output/per_resi_binding.pdb (deflated 78%)\n",
            "  adding: output/per_atom_binding.pdb (deflated 77%)\n",
            "  adding: output/monomerexample_A_predfeatures_emb1.npy (deflated 8%)\n",
            "  adding: output/monomerexample_A_pred_emb1.vtk (deflated 59%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7f2f6c19-6e8f-4ca4-936f-c951ebdfaaeb\", \"output.zip\", 4051938)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualization\n",
        "To view the predictions download the output and open the pdb file with either pymol or chimeraX. The predicted binding sites can be visualized by coloring based on the b-factor.\n",
        "\n",
        "In pymol we recommend using the command  'spectrum b, blue_white_red, minimum=0, maximum=100' for a better visualization."
      ],
      "metadata": {
        "id": "bSrKFM5eLJak"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "dMaSIF_Colab_V1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}